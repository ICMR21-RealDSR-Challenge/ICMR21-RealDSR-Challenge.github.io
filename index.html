<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>ICMR21-RealDSR-Challenge</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Challenge Title" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://icmr21-realdsr-challenge.github.io/" />
<meta property="og:url" content="https://icmr21-realdsr-challenge.github.io/" />
<meta property="og:site_name" content="ICMR21-RealDSR-Challenge.github.io" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Challenge Title" />
<script type="application/ld+json">

{"name":"ICMR21-RealDSR-Challenge.github.io","url":"https://icmr21-realdsr-challenge.github.io/","@type":"WebSite","headline":"Challenge Title","@context":"https://schema.org"}

</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="assets/css/style.css?v=d5294959e5f587b7d15b334e791d04c6661bc7f3">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
        <img src="assets/images/icmr.png" style="width: 20em;">
        <h1 class="project-name">ACM International Conference on Multimedia Retrieval 2021    </h1>
        <h2 class="project-tagline" style="margin-bottom: 0rem;font-weight: 600;">Real DSR Challenge</h2>
        <h2 class="project-tagline" style="margin-block-start: 0.1em">Real World Depth Map Super-Resolution on the RGB-D-D Dataset</h2>
      </header>

    <main id="content" class="main-content" role="main">
      <h2 id="challenge-title">Challenge Title:</h2>
      <p>Real DSR Challenge: Real World Depth Map Super-Resolution on the RGB-D-D Dataset</p>
      <p><b style="color: #990000;">Registration URL:</b> <a href="https://competitions.codalab.org/competitions/34235">HERE</a>!</p>
      <h2 id="challenge-description">Challenge Description:</h2>
      <p>As a supplement of the RGB modality, the depth map can provide useful depth information, which has been applied in bokeh rendering, AR modeling, face recognition, gesture recognition, etc. However, the resolution of depth maps cannot match the resolution of RGB images, thereby limiting the practical applications to some extent. Although numerous deep learning methods have been proposed for depth map SR and presented impressive performance, there are still some unsatisfactory points in detail preserving, computation complexity, and real-world application.</p>

      <p>In order to be applied on the platforms of the mobile devices and embedded systems, the depth map SR algorithms should take into account both the efficiency and accuracy. Furthermore, down-sampling as a straight-forward strategy has been widely used in the existing depth map SR algorithms to construct paired HR and LR depth maps training samples, which fails to simulate the real correspondences between HR and LR depth maps. 
      In this competition, we encourage the participants to design depth map SR models that can suit the real-world depth map SR task. Giving depth maps captured by low-power depth sensor, they are supposed to be up-sampled not only fit for embedded systems but also achieve high accuracy at the same time.</p>

      <h2 id="dataset-download">Dataset Download:</h2>
      <p>We randomly split 1586 portraits, 380 plants, 249 models from RGB-D-D dataset as the training set for this challenge. Meanwhile, we randomly select 50 samples from the test set in RGB-D-D dataset to evaluate your models by two phases.
      The dataset can only be used for academic purposes. By using this dataset and related codes, you should agree to cite our dataset and baseline paper. You can apply the training set and get more detailed content according to the home page of our group: <a href="http://mepro.bjtu.edu.cn/resource.html">http://mepro.bjtu.edu.cn/resource.html</a></p>

      <h2 id="baseline-method-fdsr">Baseline Method (FDSR):</h2>
      <p>Our previous work will be used as the baseline method for this challenge, which is accepted by CVPR 2021 with high performance. This paper is also used to provide the dataset in this challenge.</p>

      <p>The source code for the baseline method (FDSR) can be found: <a href="https://github.com/lingzhi96/RGB-D-D-Dataset">https://github.com/lingzhi96/RGB-D-D-Dataset</a>. Please cite our baseline paper if it is helpful for your research:</p>

      <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{he2021towards,
        title={Towards Fast and Accurate Real-World Depth Super-Resolution: Benchmark Dataset and Baseline},
        author={He, Lingzhi and Zhu, Hongguang and Li, Feng and Bai, Huihui and Cong, Runmin and Zhang, Chunjie and Lin, Chunyu and Liu, Meiqin and Zhao, Yao},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        pages={9229--9238},
        year={2021}
      }
      </code></pre></div></div>
      <h2 id="important-dates">Important Dates:</h2>
      <p>Registration Start Date: 		<strong>August 10, 2021</strong> </p>
      <p>Training Dataset Available Date: 	<strong>August 10, 2021</strong> </p>
      <p>Test Dataset Available Data:		<strong>October 10, 2021</strong> </p>
      <p>First-phase Submission Start Date:	<strong>October 10, 2021</strong> </p>
      <p>First-phase Submission Deadline: 	<strong>October 17, 2021</strong> </p>
      <p>Second-phase Submission Start Date: <strong>October 20, 2021</strong> </p>
      <p>Second-phase Submission Deadline: 	<strong>October 27, 2021</strong> </p>
      <p>Winner Announcement Date Around: 	<strong>October 30, 2021</strong></p>

      <h2 id="challenge-procedures">Challenge Procedures:</h2>
      <p>The Training set (a subset of RGB-D-D dataset) for this challenge will be available to the participants once the challenge starts. The participates are required to use the provided training set with annotations to develop a depth map super-resolution method using the low-resolution depth maps as the input or use RGB image to guide it. We will release our testing samples according to schedule. 
      There will be two phases for this challenge:</p>
      <ul>
        <li>First phase: randomly select 20 samples from the 50 testing set for evaluation.</li>
        <li>Second phase: the remaining 30 of the testing set. The final ranking is based on the smaller RMSE of the two phases. If the RMSE results are the same, we choose the one with a smaller model size.</li>
      </ul>

      <p>Some detailed rules are listed as follows:</p>

      <ul>
        <li>The total number of the participants in each team should be no more than 5. As for every participant, it is not allowed to join more than one team.</li>
        <li>The participants are <b>NOT</b> allowed to use external data for either training or validation.</li>
        <li>The teams need to provide their opensource code through GitHub after the challenge results announcement.</li>
        <li>The participants are <b>NOT</b> allowed to use extra information from human labeling on the training dataset or testing dataset for the challenge’s target labels.</li>
        <li>During each of the two phases in the competition, each team can only submit their results for evaluation less than <b>5 attempts</b> in total.</li>
        <li>The provided dataset can only be used for <b>academic purposes</b>. By using this dataset and related software, you agree to cite our dataset and baseline paper.</li>
        <li><b>The first three participants in each phase will be issued certificates.</b></li>
      </ul>

      <h2 id="host-organization">Host Organization:</h2>
      <p>MePro, Institute of Information Science, Beijing Jiaotong University</p>
      <p>Department of Computer Science,  City University of Hong Kong</p>
      <h2 id="organizers">Organizers:</h2>
      <ul>
          <li><strong>Yao Zhao</strong> (yzhao@bjtu.edu.cn): Professor, Beijing Jiaotong University
          <li><strong>Runmin Cong</strong> (rmcong@bjtu.edu.cn): Associate Professor, Beijing Jiaotong University
          <li><strong>Huihui Bai</strong> (hhbai@bjtu.edu.cn): Professor, Beijing Jiaotong University
          <li><strong>Chunjie Zhang</strong> (cjzhang@bjtu.edu.cn): Professor, Beijing Jiaotong University
          <li><strong>Chunyu Lin</strong> (cylin@bjtu.edu.cn): Professor, Beijing Jiaotong University
          <li><strong>Meiqin Liu</strong> (mqliu@bjtu.edu.cn): Associate Professor, Beijing Jiaotong University
          <li><strong>Sam Kwong</strong> (cssamk@cityu.edu.hk): Chair Professor, City University of Hong Kong
      </ul>
    <footer class="site-footer">
        
    </footer>
    </main>
    <script>
      var caution=false

      function setCookie(name,value,expires,path,domain,secure)
      {
        var curCookie=name+"="+escape(value) +((expires)?";expires="+expires.toGMTString() : "") + ((path)?"; path=" + path : "") + ((domain)? "; domain=" + domain : "") +((secure)?";secure" : "")

        if(!caution||(name + "=" + escape(value)).length <= 4000)
        {
          document.cookie = curCookie
        }else if(confirm("Cookie exceeds 4KB and will be cut!")){
          document.cookie = curCookie
        }
      }

      function getCookie(name){
        var prefix = name + "="

        var cookieStartIndex = document.cookie.indexOf(prefix)

        if (cookieStartIndex == -1){
          return null
        }

        var cookieEndIndex=document.cookie.indexOf(";",cookieStartIndex+prefix.length)

        if(cookieEndIndex == -1){
          cookieEndIndex = document.cookie.length
        }

        return unescape(document.cookie.substring(cookieStartIndex+prefix.length,cookieEndIndex))

      }

      function deleteCookie(name, path, domain){
        if(getCookie(name))
        {
        document.cookie = name + "=" +((path) ? "; path=" + path : "") +((domain) ? "; domain=" + domain : "") + "; expires=Thu, 01-Jan-70 00:00:01 GMT"
        }
      }

      function fixDate(date){
        var base=new Date(0)
        var skew=base.getTime()
        if(skew>0){
          date.setTime(date.getTime()-skew)
        }

      }

      var now=new Date()

      fixDate(now)

      now.setTime(now.getTime()+365 * 24 * 60 * 60 * 1000)

      var visits = getCookie("counter")

      if(!visits)
      {
        visits=1;
      }else{
        visits=parseInt(visits)+1;
      }

      setCookie("counter", visits, now)

      document.write("您是到访的第" + visits + "位用户！")
    </script>
  </body>
</html>
